{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NTVWEj8udYap"
   },
   "source": [
    "<h2><center> Welcome to the TotalEnergies rEVolution Hackathon</h2></center>\n",
    "<figure>\n",
    "<!--<img src =\"https://drive.google.com/uc?export=view&id=1hSOAfRhJ_jo-MZAjq81VYJu5bZNL7EjD\" width = \"800\" height = '500'/> -->\n",
    "\n",
    "***Pelogue***\n",
    ">TotalEnergies Uganda welcomes you to the TotalEnergies rEVolution Hackathon, implemented by Outbox Uganda, to deliver optimal locations of EV charging points in Kampala considering several constraints like traffic, optimum coverage and population density and usage.\n",
    "\n",
    "> This challenge serves as a qualification for the grand challenge NB: This challenge serves as a qualifier to be selected for the [TotalEnergies rEVolution Hackathon ($10 000 in prizes)](https://zindi.africa/competitions/total-energies-revolution-hackathon-finals) to be hosted virtually on 18-20 September 2023. To qualify for the hackathon, you need to be in a team of 4 members and make a submission to this challenge.\n",
    "\n",
    "***About the problem***\n",
    ">TotalEnergies Uganda welcomes you to the TotalEnergies rEVolution Hackathon, implemented by Outbox Uganda, to deliver optimal locations of EV charging points in Kampala considering several constraints like traffic, optimum coverage and population density and usage.\n",
    "\n",
    ">The lack of optimal locations for electric vehicle (EV) charging points in Kampala presents a significant challenge for the adoption and usage of electric vehicles. Factors such as traffic congestion, optimum coverage, population density, and usage patterns need to be considered to ensure the effective implementation of EV charging infrastructure. Therefore, there is a need to address this problem by identifying and delivering the most suitable locations for EV charging points in Kampala.\n",
    "\n",
    ">Nairobi is one of the most heavily congested cities in Africa. Each day thousands of Kenyans make the trip into Nairobi from towns such as Kisii, Keroka, and beyond for work, business, or to visit friends and family. The journey can be long, and the final approach into the city can impact the length of the trip significantly depending on traffic. How do traffic patterns influence people's decisions to come into the city by bus and which bus to take? Does knowing the traffic patterns in Nairobi help anticipate the demand for particular routes at particular times?\n",
    "\n",
    "***Objective of this challenge***\n",
    "> The primary objective of the hackathon is to develop innovative solutions that can identify the optimal locations for EV charging points in Kampala. Participants will be encouraged to leverage data analytics, machine learning, and other relevant technologies to analyse various constraints, such as traffic patterns, coverage requirements, population density, and EV usage.\n",
    "\n",
    ">The aim of the competition is to create a predictive model using traffic data provided from Uber Movement and historic bus ticket sales data from Mobiticket to predict the number of tickets that will be sold for buses into Nairobi from cities in \"up country\" Kenya.\n",
    "\n",
    "***About the Data***\n",
    ">The data used to train the model will be historic hourly traffic patterns in Nairobi and historic ticket purchasing data for 14 bus routes into Nairobi from October 2017 to April 2018, and includes the place or origin, the scheduled time of departure, the channel used for the purchase, the type of vehicle, the capacity of the vehicle, and the assigned seat number. Zindi competitors will be allowed to create their own customized traffic datasets using the Uber Movement platform.\n",
    "\n",
    "***Evaluation metric***\n",
    "> The Mean Absolute Error will be used to evaluate accuracy of the submitted solutions. So the lower the score the better!\n",
    "\n",
    "***Relevance of the Challenge***\n",
    ">This resulting model can be used to anticipate customer demand for certain rides, to manage resources and vehicles more efficiently, to offer promotions and sell other services more effectively, such as micro-insurance, or even improve customer service by being able to send alerts and other useful information to customers\n",
    "\n",
    ">The solutions to this challenge are the first step towards solving Nairobi's traffic problems. We look forward to taking this journey with you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR-kEZqTdYay"
   },
   "source": [
    "# Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dseqR791dYay"
   },
   "source": [
    "# install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gzFAUWD_dYaz",
    "ExecuteTime": {
     "end_time": "2023-07-27T12:08:03.082352900Z",
     "start_time": "2023-07-27T12:07:26.045154500Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install watermark\n",
    "!pip install pandas-profiling\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn\n",
    "!pip install xgboost\n",
    "!pip install lightgbm\n",
    "!pip install missingno\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_mcs-wedYa1"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1690370799109,
     "user": {
      "displayName": "Michael Goboola",
      "userId": "04865625352698102762"
     },
     "user_tz": 0
    },
    "id": "sbCDKb7MdYa2",
    "ExecuteTime": {
     "end_time": "2023-07-27T12:23:50.192375900Z",
     "start_time": "2023-07-27T12:23:50.182412100Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EDps712P8d8t"
   },
   "source": [
    "### Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1690370801694,
     "user": {
      "displayName": "Michael Goboola",
      "userId": "04865625352698102762"
     },
     "user_tz": 0
    },
    "id": "8PXDMjWD8jkE",
    "ExecuteTime": {
     "end_time": "2023-07-27T12:23:55.954346700Z",
     "start_time": "2023-07-27T12:23:55.944358400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 2023\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa89jYrKdYa3"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1690371382538,
     "user": {
      "displayName": "Michael Goboola",
      "userId": "04865625352698102762"
     },
     "user_tz": 0
    },
    "id": "cyI0vPw2dYa6",
    "outputId": "fcff402f-fe7b-46cf-d127-c8bfe516a91f",
    "ExecuteTime": {
     "end_time": "2023-07-27T12:24:02.011564900Z",
     "start_time": "2023-07-27T12:24:01.779569600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   ride_id  number_of_ticket\n0     4446                 0\n1    13962                 0\n2     5569                 0\n3     1675                 0\n4     5711                 0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ride_id</th>\n      <th>number_of_ticket</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4446</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13962</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5569</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1675</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5711</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load files\n",
    "train_1 = pd.read_csv(os.path.join('../TotalEnergies/data/Train.csv'))\n",
    "test_1 = pd.read_csv(os.path.join('../TotalEnergies/data/Test.csv'))\n",
    "test = pd.read_csv('../TotalEnergies/data/Test.csv', parse_dates=['travel_date'], dayfirst=True).drop(['car_type', 'travel_to'], axis=1)\n",
    "df = pd.read_csv('../TotalEnergies/data/Train.csv', parse_dates=['travel_date'], dayfirst=True)\n",
    "train = df.groupby(['ride_id', 'travel_date', 'travel_time', 'travel_from', 'max_capacity']).size().reset_index(name='Count') #sort=False if needed?\n",
    "\n",
    "submission = pd.read_csv(os.path.join('../TotalEnergies/submissions/SampleSubmission.csv'))\n",
    "\n",
    "# Preview train dataset\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "   ride_id travel_date travel_time travel_from  max_capacity\n0     4446  2018-04-27       09:00       Kisii            11\n1    13962  2018-04-23       07:10    Homa Bay            49\n2     5569  2018-04-24       07:20       Kisii            11\n3     1675  2018-05-01       11:01       Kisii            11\n4     5711  2018-04-22       10:51       Kisii            11",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ride_id</th>\n      <th>travel_date</th>\n      <th>travel_time</th>\n      <th>travel_from</th>\n      <th>max_capacity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4446</td>\n      <td>2018-04-27</td>\n      <td>09:00</td>\n      <td>Kisii</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13962</td>\n      <td>2018-04-23</td>\n      <td>07:10</td>\n      <td>Homa Bay</td>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5569</td>\n      <td>2018-04-24</td>\n      <td>07:20</td>\n      <td>Kisii</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1675</td>\n      <td>2018-05-01</td>\n      <td>11:01</td>\n      <td>Kisii</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5711</td>\n      <td>2018-04-22</td>\n      <td>10:51</td>\n      <td>Kisii</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview test dataset\n",
    "test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T12:24:06.139559400Z",
     "start_time": "2023-07-27T12:24:06.127542500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "            ride_id  max_capacity        Count\ncount   6249.000000   6249.000000  6249.000000\nmean    9963.644583     30.392223     8.264522\nstd     2296.304872     18.997471     8.632968\nmin     1442.000000     11.000000     1.000000\n25%     7989.000000     11.000000     2.000000\n50%    10024.000000     49.000000     7.000000\n75%    11917.000000     49.000000    11.000000\nmax    20117.000000     49.000000    50.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ride_id</th>\n      <th>max_capacity</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6249.000000</td>\n      <td>6249.000000</td>\n      <td>6249.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>9963.644583</td>\n      <td>30.392223</td>\n      <td>8.264522</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2296.304872</td>\n      <td>18.997471</td>\n      <td>8.632968</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1442.000000</td>\n      <td>11.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>7989.000000</td>\n      <td>11.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>10024.000000</td>\n      <td>49.000000</td>\n      <td>7.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>11917.000000</td>\n      <td>49.000000</td>\n      <td>11.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>20117.000000</td>\n      <td>49.000000</td>\n      <td>50.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview train dataset\n",
    "train.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T12:24:35.749405500Z",
     "start_time": "2023-07-27T12:24:35.710404400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bx4J2YbwdYa7"
   },
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbqOzyCadYa7"
   },
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "0vN1LSTmdYa8",
    "ExecuteTime": {
     "end_time": "2023-07-27T12:09:00.556185900Z",
     "start_time": "2023-07-27T12:09:00.545198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (6249, 6)\n",
      "Test shape:  (889, 5)\n",
      "Submission shape:  (889, 2)\n"
     ]
    }
   ],
   "source": [
    "# check the shape of the data\n",
    "print(\"Train shape: \", train.shape)\n",
    "print(\"Test shape: \", test.shape)\n",
    "print(\"Submission shape: \", submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWoAoOucdYa-"
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Ejv5Fg-KdYa_",
    "ExecuteTime": {
     "end_time": "2023-07-27T12:09:05.873227400Z",
     "start_time": "2023-07-27T12:09:05.858185400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "test[\"travel_time\"] = test[\"travel_time\"].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))\n",
    "test['day'] = test['travel_date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "U_b7BvUWdYa_",
    "ExecuteTime": {
     "end_time": "2023-07-27T12:09:09.018218600Z",
     "start_time": "2023-07-27T12:09:09.000201500Z"
    }
   },
   "outputs": [],
   "source": [
    "train['t'] = 0\n",
    "test['t'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "w7h3qaaGdYa_",
    "ExecuteTime": {
     "end_time": "2023-07-27T12:09:15.389267400Z",
     "start_time": "2023-07-27T12:09:15.373222200Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.concat([train, test], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "q-GEmcbndYa_",
    "ExecuteTime": {
     "end_time": "2023-07-27T12:09:18.055049800Z",
     "start_time": "2023-07-27T12:09:18.039047Z"
    }
   },
   "outputs": [],
   "source": [
    "Xd = pd.get_dummies(X, columns=['travel_from', 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ztfkWImldYbA",
    "ExecuteTime": {
     "end_time": "2023-07-27T12:09:23.526925200Z",
     "start_time": "2023-07-27T12:09:23.493918200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   ride_id travel_date travel_time  max_capacity  Count  t  \\\n0     1442  2017-10-17        7:15            49    1.0  0   \n1     5437  2017-11-19        7:12            49    1.0  0   \n2     5710  2017-11-26        7:05            49    1.0  0   \n3     5777  2017-11-27        7:10            49    5.0  0   \n4     5778  2017-11-27        7:12            49   31.0  0   \n\n   travel_from_Awendo  travel_from_Homa Bay  travel_from_Kehancha  \\\n0                   0                     0                     0   \n1                   0                     0                     0   \n2                   0                     0                     0   \n3                   0                     1                     0   \n4                   0                     0                     0   \n\n   travel_from_Kendu Bay  ...  travel_from_Rongo  travel_from_Sirare  \\\n0                      0  ...                  0                   0   \n1                      0  ...                  0                   0   \n2                      0  ...                  0                   0   \n3                      0  ...                  0                   0   \n4                      0  ...                  0                   0   \n\n   travel_from_Sori  day_0.0  day_1.0  day_2.0  day_3.0  day_4.0  day_5.0  \\\n0                 0        0        0        0        0        0        0   \n1                 0        0        0        0        0        0        0   \n2                 0        0        0        0        0        0        0   \n3                 0        0        0        0        0        0        0   \n4                 0        0        0        0        0        0        0   \n\n   day_6.0  \n0        0  \n1        0  \n2        0  \n3        0  \n4        0  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ride_id</th>\n      <th>travel_date</th>\n      <th>travel_time</th>\n      <th>max_capacity</th>\n      <th>Count</th>\n      <th>t</th>\n      <th>travel_from_Awendo</th>\n      <th>travel_from_Homa Bay</th>\n      <th>travel_from_Kehancha</th>\n      <th>travel_from_Kendu Bay</th>\n      <th>...</th>\n      <th>travel_from_Rongo</th>\n      <th>travel_from_Sirare</th>\n      <th>travel_from_Sori</th>\n      <th>day_0.0</th>\n      <th>day_1.0</th>\n      <th>day_2.0</th>\n      <th>day_3.0</th>\n      <th>day_4.0</th>\n      <th>day_5.0</th>\n      <th>day_6.0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1442</td>\n      <td>2017-10-17</td>\n      <td>7:15</td>\n      <td>49</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5437</td>\n      <td>2017-11-19</td>\n      <td>7:12</td>\n      <td>49</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5710</td>\n      <td>2017-11-26</td>\n      <td>7:05</td>\n      <td>49</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5777</td>\n      <td>2017-11-27</td>\n      <td>7:10</td>\n      <td>49</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5778</td>\n      <td>2017-11-27</td>\n      <td>7:12</td>\n      <td>49</td>\n      <td>31.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 30 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "HQ7IZ7xfdYbA",
    "ExecuteTime": {
     "end_time": "2023-07-27T12:22:48.479775600Z",
     "start_time": "2023-07-27T12:22:48.401805500Z"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Time in minutes\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m train[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtravel_time\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtravel_time\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m:\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m60\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m train[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtravel_time\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mhead()\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\hackthons\\lib\\site-packages\\pandas\\core\\series.py:4771\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4661\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4662\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4663\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4666\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4667\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4668\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4669\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4670\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4769\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4770\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4771\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\hackthons\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[0;32m   1122\u001B[0m \u001B[38;5;66;03m# self.f is Callable\u001B[39;00m\n\u001B[1;32m-> 1123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\hackthons\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1172\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1173\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[1;32m-> 1174\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1175\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1176\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1177\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1178\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1181\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1182\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\hackthons\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Cell \u001B[1;32mIn[37], line 2\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Time in minutes\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m train[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtravel_time\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m train[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtravel_time\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28mint\u001B[39m(\u001B[43mx\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m60\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mint\u001B[39m(x[\u001B[38;5;241m2\u001B[39m]))\n\u001B[0;32m      3\u001B[0m train[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtravel_time\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mhead()\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Time in minutes\n",
    "train[\"travel_time\"] = train[\"travel_time\"].str.split(':').apply(lambda x: int(x[1]) * 60 + int(x[2]))\n",
    "train[\"travel_time\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "train['day'] = train['travel_date'].dt.dayofweek"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T12:21:56.372618400Z",
     "start_time": "2023-07-27T12:21:56.360623900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIafv3ordYbG"
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '7:15'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m y_train \u001B[38;5;241m=\u001B[39m Xd\u001B[38;5;241m.\u001B[39mloc[Xd[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCount\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m      3\u001B[0m regr \u001B[38;5;241m=\u001B[39m RandomForestRegressor(n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m500\u001B[39m, criterion\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabsolute_error\u001B[39m\u001B[38;5;124m\"\u001B[39m, max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m \u001B[43mregr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\hackthons\\lib\\site-packages\\sklearn\\base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1149\u001B[0m     )\n\u001B[0;32m   1150\u001B[0m ):\n\u001B[1;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\hackthons\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:348\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(y):\n\u001B[0;32m    347\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse multilabel-indicator for y is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 348\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    352\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\hackthons\\lib\\site-packages\\sklearn\\base.py:621\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    619\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    620\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 621\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    622\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    624\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\hackthons\\lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1142\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1144\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1145\u001B[0m     )\n\u001B[1;32m-> 1147\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1148\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1149\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1150\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1151\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1152\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1153\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1154\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1155\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1156\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1157\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1158\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1159\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1160\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1161\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1163\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[0;32m   1165\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\hackthons\\lib\\site-packages\\sklearn\\utils\\validation.py:917\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    915\u001B[0m         array \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(array, dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    916\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 917\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43m_asarray_with_order\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    918\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[0;32m    919\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    920\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[0;32m    921\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\hackthons\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001B[0m, in \u001B[0;36m_asarray_with_order\u001B[1;34m(array, dtype, order, copy, xp)\u001B[0m\n\u001B[0;32m    378\u001B[0m     array \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39marray(array, order\u001B[38;5;241m=\u001B[39morder, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    379\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 380\u001B[0m     array \u001B[38;5;241m=\u001B[39m \u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001B[39;00m\n\u001B[0;32m    383\u001B[0m \u001B[38;5;66;03m# container that is consistent with the input's namespace.\u001B[39;00m\n\u001B[0;32m    384\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39masarray(array)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\hackthons\\lib\\site-packages\\pandas\\core\\generic.py:2070\u001B[0m, in \u001B[0;36mNDFrame.__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m   2069\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__array__\u001B[39m(\u001B[38;5;28mself\u001B[39m, dtype: npt\u001B[38;5;241m.\u001B[39mDTypeLike \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m-> 2070\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: '7:15'"
     ]
    }
   ],
   "source": [
    "X_train = Xd.loc[Xd['t'] == 0].drop(['Count', 'ride_id', 'travel_date'], axis=1)\n",
    "y_train = Xd.loc[Xd['t'] == 0]['Count']\n",
    "regr = RandomForestRegressor(n_estimators=500, criterion=\"absolute_error\", max_depth=10, n_jobs=-1)\n",
    "regr.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T12:20:35.031536900Z",
     "start_time": "2023-07-27T12:20:34.869549200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(mean_absolute_error(regr.predict(X_train), y_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOXC1hSkdYbj"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test = Xd.loc[Xd['t'] == 1].drop(['Count', 'ride_id', 'travel_date'], axis=1)\n",
    "pred = regr.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FwkcTS7xdYbj"
   },
   "source": [
    "\n",
    "# Create Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission['number_of_ticket'][5:] = pred[5:]\n",
    "submission.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0B2H2pm1dYbk"
   },
   "source": [
    "# Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "tYG1c9HidYbk",
    "ExecuteTime": {
     "end_time": "2023-07-26T12:02:58.653684200Z",
     "start_time": "2023-07-26T12:02:58.644685Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('number_of_ticket.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_t6ZUzBYdYbl"
   },
   "source": [
    "# References"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/michaelgobz/hackthons/blob/main/colab/TotalEnergies/TotalEnergies%20rEVolution%20Hackathon.ipynb",
     "timestamp": 1690312798060
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
