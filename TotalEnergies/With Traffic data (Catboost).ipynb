{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install catboost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T10:13:30.948920600Z",
     "start_time": "2023-07-31T10:13:23.532710300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T10:13:34.679123700Z",
     "start_time": "2023-07-31T10:13:34.305440500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\AppData\\Local\\Temp\\ipykernel_11424\\1301998871.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv('../TotalEnergies/data/Train.csv', parse_dates=['travel_date'], dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "# Load training data, reshape, add departure time as an integer number of seconds and add day of week:\n",
    "df = pd.read_csv('../TotalEnergies/data/Train.csv', parse_dates=['travel_date'], dayfirst=True)\n",
    "train = df.groupby(['ride_id', 'travel_date', 'travel_time', 'travel_from', 'max_capacity']).size().reset_index(name='Count') #sort=False if needed?\n",
    "train[\"travel_time\"] = train[\"travel_time\"].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))\n",
    "train['day'] = train['travel_date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T10:13:56.384130100Z",
     "start_time": "2023-07-31T10:13:56.352788600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\AppData\\Local\\Temp\\ipykernel_11424\\924476196.py:2: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  test = pd.read_csv('../TotalEnergies/data/Test.csv', parse_dates=['travel_date'], dayfirst=True).drop(['car_type', 'travel_to'], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# The same for the test data\n",
    "test = pd.read_csv('../TotalEnergies/data/Test.csv', parse_dates=['travel_date'], dayfirst=True).drop(['car_type', 'travel_to'], axis=1)\n",
    "test[\"travel_time\"] = test[\"travel_time\"].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))\n",
    "test['day'] = test['travel_date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T10:14:26.471953400Z",
     "start_time": "2023-07-31T10:14:26.456315700Z"
    }
   },
   "outputs": [],
   "source": [
    "# The sample submission file\n",
    "sample = pd.read_csv('../TotalEnergies/submissions/SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T10:14:30.917034700Z",
     "start_time": "2023-07-31T10:14:30.885339800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine training and test data for now, so that we can add uber movement data all in one go\n",
    "train['t'] = 0\n",
    "test['t'] = 1\n",
    "X = pd.concat([train, test], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T10:14:36.457483600Z",
     "start_time": "2023-07-31T10:14:34.071437400Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'Date'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 8\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Load travel times from Uber movement data ( 3 x 3month periods)\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mt1 = pd.read_csv('../TotalEnergies/data/Travel_Times_Daily_1.csv',parse_dates=['Date'])\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03mt2 = pd.read_csv('../TotalEnergies/data/Travel_Times_Daily_2.csv',parse_dates=['Date'])\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03mt3 = pd.read_csv('../TotalEnergies/data/Travel_Times_Daily_3.csv',parse_dates=['Date'])\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 8\u001B[0m t4 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../TotalEnergies/data/Travel_Times_Awendo.csv\u001B[39m\u001B[38;5;124m'\u001B[39m,parse_dates\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      9\u001B[0m t5 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../TotalEnergies/data/Travel_Times_HomaBay.csv\u001B[39m\u001B[38;5;124m'\u001B[39m,parse_dates\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     10\u001B[0m t6 \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../TotalEnergies/data/Travel_Times_Kehancha.csv\u001B[39m\u001B[38;5;124m'\u001B[39m,parse_dates\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\hackthons\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m    899\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    900\u001B[0m     dialect,\n\u001B[0;32m    901\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    908\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m    909\u001B[0m )\n\u001B[0;32m    910\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 912\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\hackthons\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    574\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    576\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 577\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    579\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    580\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\hackthons\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1404\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1406\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1407\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_engine(f, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine)\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\hackthons\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1679\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1676\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m   1678\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1679\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m mapping[engine](f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions)\n\u001B[0;32m   1680\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1681\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\hackthons\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:161\u001B[0m, in \u001B[0;36mCParserWrapper.__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m    155\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_usecols_names(\n\u001B[0;32m    156\u001B[0m             usecols,\n\u001B[0;32m    157\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnames,  \u001B[38;5;66;03m# type: ignore[has-type]\u001B[39;00m\n\u001B[0;32m    158\u001B[0m         )\n\u001B[0;32m    160\u001B[0m \u001B[38;5;66;03m# error: Cannot determine type of 'names'\u001B[39;00m\n\u001B[1;32m--> 161\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_parse_dates_presence(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnames)  \u001B[38;5;66;03m# type: ignore[has-type]\u001B[39;00m\n\u001B[0;32m    162\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_noconvert_columns()\n\u001B[0;32m    164\u001B[0m \u001B[38;5;66;03m# error: Cannot determine type of 'names'\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\hackthons\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:230\u001B[0m, in \u001B[0;36mParserBase._validate_parse_dates_presence\u001B[1;34m(self, columns)\u001B[0m\n\u001B[0;32m    220\u001B[0m missing_cols \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[0;32m    221\u001B[0m     \u001B[38;5;28msorted\u001B[39m(\n\u001B[0;32m    222\u001B[0m         {\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    227\u001B[0m     )\n\u001B[0;32m    228\u001B[0m )\n\u001B[0;32m    229\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m missing_cols:\n\u001B[1;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    231\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing column provided to \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mparse_dates\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmissing_cols\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    232\u001B[0m     )\n\u001B[0;32m    233\u001B[0m \u001B[38;5;66;03m# Convert positions to actual column names\u001B[39;00m\n\u001B[0;32m    234\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[0;32m    235\u001B[0m     col \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(col, \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m columns) \u001B[38;5;28;01melse\u001B[39;00m columns[col]\n\u001B[0;32m    236\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m cols_needed\n\u001B[0;32m    237\u001B[0m ]\n",
      "\u001B[1;31mValueError\u001B[0m: Missing column provided to 'parse_dates': 'Date'"
     ]
    }
   ],
   "source": [
    "# Load travel times from Uber movement data ( 3 x 3month periods)\n",
    "\"\"\"\n",
    "t1 = pd.read_csv('../TotalEnergies/data/Travel_Times_Daily_1.csv',parse_dates=['Date'])\n",
    "t2 = pd.read_csv('../TotalEnergies/data/Travel_Times_Daily_2.csv',parse_dates=['Date'])\n",
    "t3 = pd.read_csv('../TotalEnergies/data/Travel_Times_Daily_3.csv',parse_dates=['Date'])\n",
    "\"\"\"\n",
    "\n",
    "t4 = pd.read_csv('../TotalEnergies/data/Travel_Times_Awendo.csv',parse_dates=['Date'])\n",
    "t5 = pd.read_csv('../TotalEnergies/data/Travel_Times_HomaBay.csv',parse_dates=['Date'])\n",
    "t6 = pd.read_csv('../TotalEnergies/data/Travel_Times_Kehancha.csv',parse_dates=['Date'])\n",
    "t7 = pd.read_csv('../TotalEnergies/data/Travel_Times_KenduBay.csv',parse_dates=['Date'])\n",
    "t8 = pd.read_csv('../TotalEnergies/data/Travel_Times_Keroka.csv',parse_dates=['Date'])\n",
    "t9 = pd.read_csv('../TotalEnergies/data/Travel_Times_Keumbu.csv',parse_dates=['Date'])\n",
    "t10 = pd.read_csv('../TotalEnergies/data/Travel_Times_Kijauri.csv',parse_dates=['Date'])\n",
    "t11 = pd.read_csv('../TotalEnergies/data/Travel_Times_Kisii.csv',parse_dates=['Date'])\n",
    "t12 = pd.read_csv('../TotalEnergies/data/Travel_Times_Mbita.csv',parse_dates=['Date'])\n",
    "t13 = pd.read_csv('../TotalEnergies/data/Travel_Times_Migori.csv',parse_dates=['Date'])\n",
    "t14 = pd.read_csv('../TotalEnergies/data/Travel_Times_Ndhiwa.csv',parse_dates=['Date'])\n",
    "t15 = pd.read_csv('../TotalEnergies/data/Travel_Times_Nyachenge.csv',parse_dates=['Date'])\n",
    "t16 = pd.read_csv('../TotalEnergies/data/Travel_Times_Oyugis.csv',parse_dates=['Date'])\n",
    "t17 = pd.read_csv('../TotalEnergies/data/Travel_Times_Rodi.csv',parse_dates=['Date'])\n",
    "t18 = pd.read_csv('../TotalEnergies/data/Travel_Times_Rongo.csv',parse_dates=['Date'])\n",
    "t19 = pd.read_csv('../TotalEnergies/data/Travel_Times_Sirare.csv',parse_dates=['Date'])\n",
    "t20 = pd.read_csv('../TotalEnergies/data/Travel_Times_Sori.csv',parse_dates=['Date'])\n",
    "\n",
    "\n",
    "\n",
    "travel_times = pd.concat([t4, t5, t6, t7, t8, t9, t10, t11, t12, t13, t14, t15, t16, t17, t18, t19, t20], ignore_index=True)\n",
    "travel_times = travel_times.fillna(method='ffill')[['Daily Mean Travel Time (Seconds)', 'Date']]\n",
    "travel_times['Date'] = pd.to_datetime(travel_times['Date'])\n",
    "travel_times.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T13:29:36.450014400Z",
     "start_time": "2023-07-27T13:29:36.421020400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   ride_id  travel_time travel_from  max_capacity  Count  day  t       Date  \\\n0     1442          435      Migori            49    1.0    1  0 2017-10-17   \n\n   Daily Mean Travel Time (Seconds)  \n0                            2698.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ride_id</th>\n      <th>travel_time</th>\n      <th>travel_from</th>\n      <th>max_capacity</th>\n      <th>Count</th>\n      <th>day</th>\n      <th>t</th>\n      <th>Date</th>\n      <th>Daily Mean Travel Time (Seconds)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1442</td>\n      <td>435</td>\n      <td>Migori</td>\n      <td>49</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2017-10-17</td>\n      <td>2698.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with our contest data\n",
    "X['Date'] = X['travel_date']\n",
    "X.set_index('travel_date', inplace=True)\n",
    "X = X.merge(travel_times, how='left', on='Date')\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T13:35:14.916598200Z",
     "start_time": "2023-07-27T13:35:14.908599Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = CatBoostRegressor(iterations=200, \n",
    "                          depth=4, \n",
    "                          learning_rate=0.5, \n",
    "                          loss_function='MAE', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T13:35:24.213113900Z",
     "start_time": "2023-07-27T13:35:24.205116300Z"
    }
   },
   "outputs": [],
   "source": [
    "in_cols = ['travel_time', 'travel_from', 'max_capacity', 'day'] #'Daily Mean Travel Time (Seconds)' as an option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T13:35:28.509021500Z",
     "start_time": "2023-07-27T13:35:26.681033600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostRegressor at 0x25b0d142310>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "tr = X.loc[X.t == 0]\n",
    "model.fit(tr[in_cols], tr['Count'], cat_features=['travel_from', 'max_capacity', 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T13:35:33.421974400Z",
     "start_time": "2023-07-27T13:35:33.411963700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.499389595249243\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "print(mean_absolute_error(model.predict(tr[in_cols]), tr['Count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-27T13:35:41.114893100Z",
     "start_time": "2023-07-27T13:35:41.092880400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   ride_id  number_of_ticket\n0     4446          0.000000\n1    13962          0.000000\n2     5569          0.000000\n3     1675          0.000000\n4     5711          0.000000\n5     2417          9.778770\n6    15010         14.936669\n7     1823          9.622466\n8    15191          9.856025\n9    14402          1.651639",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ride_id</th>\n      <th>number_of_ticket</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4446</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13962</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5569</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1675</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5711</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2417</td>\n      <td>9.778770</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>15010</td>\n      <td>14.936669</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1823</td>\n      <td>9.622466</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>15191</td>\n      <td>9.856025</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>14402</td>\n      <td>1.651639</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions and append to the sample submission data, and save as csv\n",
    "te = X.loc[X.t == 1]\n",
    "te[in_cols].head()\n",
    "te = X.loc[X.t == 1]\n",
    "sample['number_of_ticket'][5:] = model.predict(te[in_cols])[5:] # Ignore the warning\n",
    "sample.to_csv('catboost_predictions.csv', index=False)\n",
    "sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
