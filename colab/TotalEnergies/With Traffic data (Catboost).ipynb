{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h2><center> Welcome to the TotalEnergies rEVolution Hackathon</h2></center>\n",
    "<figure>\n",
    "<!--<img src =\"https://drive.google.com/uc?export=view&id=1hSOAfRhJ_jo-MZAjq81VYJu5bZNL7EjD\" width = \"800\" height = '500'/> -->\n",
    "\n",
    "***Pelogue***\n",
    ">TotalEnergies Uganda welcomes you to the TotalEnergies rEVolution Hackathon, implemented by Outbox Uganda, to deliver optimal locations of EV charging points in Kampala considering several constraints like traffic, optimum coverage and population density and usage.\n",
    "\n",
    "> This challenge serves as a qualification for the grand challenge NB: This challenge serves as a qualifier to be selected for the [TotalEnergies rEVolution Hackathon ($10 000 in prizes)](https://zindi.africa/competitions/total-energies-revolution-hackathon-finals) to be hosted virtually on 18-20 September 2023. To qualify for the hackathon, you need to be in a team of 4 members and make a submission to this challenge.\n",
    "\n",
    "***About the problem***\n",
    ">TotalEnergies Uganda welcomes you to the TotalEnergies rEVolution Hackathon, implemented by Outbox Uganda, to deliver optimal locations of EV charging points in Kampala considering several constraints like traffic, optimum coverage and population density and usage.\n",
    "\n",
    ">The lack of optimal locations for electric vehicle (EV) charging points in Kampala presents a significant challenge for the adoption and usage of electric vehicles. Factors such as traffic congestion, optimum coverage, population density, and usage patterns need to be considered to ensure the effective implementation of EV charging infrastructure. Therefore, there is a need to address this problem by identifying and delivering the most suitable locations for EV charging points in Kampala.\n",
    "\n",
    ">Nairobi is one of the most heavily congested cities in Africa. Each day thousands of Kenyans make the trip into Nairobi from towns such as Kisii, Keroka, and beyond for work, business, or to visit friends and family. The journey can be long, and the final approach into the city can impact the length of the trip significantly depending on traffic. How do traffic patterns influence people's decisions to come into the city by bus and which bus to take? Does knowing the traffic patterns in Nairobi help anticipate the demand for particular routes at particular times?\n",
    "\n",
    "***Objective of this challenge***\n",
    "> The primary objective of the hackathon is to develop innovative solutions that can identify the optimal locations for EV charging points in Kampala. Participants will be encouraged to leverage data analytics, machine learning, and other relevant technologies to analyse various constraints, such as traffic patterns, coverage requirements, population density, and EV usage.\n",
    "\n",
    ">The aim of the competition is to create a predictive model using traffic data provided from Uber Movement and historic bus ticket sales data from Mobiticket to predict the number of tickets that will be sold for buses into Nairobi from cities in \"up country\" Kenya.\n",
    "\n",
    "***About the Data***\n",
    ">The data used to train the model will be historic hourly traffic patterns in Nairobi and historic ticket purchasing data for 14 bus routes into Nairobi from October 2017 to April 2018, and includes the place or origin, the scheduled time of departure, the channel used for the purchase, the type of vehicle, the capacity of the vehicle, and the assigned seat number. Zindi competitors will be allowed to create their own customized traffic datasets using the Uber Movement platform.\n",
    "\n",
    "***Evaluation metric***\n",
    "> The Mean Absolute Error will be used to evaluate accuracy of the submitted solutions. So the lower the score the better!\n",
    "\n",
    "***Relevance of the Challenge***\n",
    ">This resulting model can be used to anticipate customer demand for certain rides, to manage resources and vehicles more efficiently, to offer promotions and sell other services more effectively, such as micro-insurance, or even improve customer service by being able to send alerts and other useful information to customers\n",
    "\n",
    ">The solutions to this challenge are the first step towards solving Nairobi's traffic problems. We look forward to taking this journey with you!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Install the required libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (1.2)\n",
      "Requirement already satisfied: graphviz in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from catboost) (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from catboost) (1.25.0)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from catboost) (2.0.3)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: plotly in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from catboost) (5.15.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from pandas>=0.24->catboost) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from matplotlib->catboost) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from matplotlib->catboost) (4.41.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from matplotlib->catboost) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from matplotlib->catboost) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\programdata\\anaconda3\\envs\\hackthons\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "Collecting google.colab\n",
      "  Using cached google-colab-1.0.0.tar.gz (72 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google-auth~=1.4.0 (from google.colab)\n",
      "  Using cached google_auth-1.4.2-py2.py3-none-any.whl (64 kB)\n",
      "Collecting ipykernel~=4.6.0 (from google.colab)\n",
      "  Using cached ipykernel-4.6.1-py3-none-any.whl (104 kB)\n",
      "Collecting ipython~=5.5.0 (from google.colab)\n",
      "  Using cached ipython-5.5.0-py3-none-any.whl (758 kB)\n",
      "Collecting notebook~=5.2.0 (from google.colab)\n",
      "  Using cached notebook-5.2.2-py2.py3-none-any.whl (8.0 MB)\n",
      "Collecting six~=1.12.0 (from google.colab)\n",
      "  Using cached six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pandas~=0.24.0 (from google.colab)\n",
      "  Using cached pandas-0.24.2.tar.gz (11.8 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  C:\\Users\\michael\\AppData\\Local\\Temp\\pip-install-mwb0nqhd\\pandas_29ea84b1f7c7445fb58aceeac05bd9c7\\setup.py:12: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "    import pkg_resources\n",
      "  C:\\ProgramData\\anaconda3\\envs\\hackthons\\Lib\\site-packages\\setuptools\\__init__.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Requirements should be satisfied by a PEP 517 installer.\n",
      "          If you are using pip, you can try `pip install --use-pep517`.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    dist.fetch_build_eggs(dist.setup_requires)\n",
      "  error in pandas setup command: 'install_requires' must be a string or list of strings containing valid project/version requirement specifiers; Expected end or semicolon (after version specifier)\n",
      "      pytz >= 2011k\n",
      "           ~~~~~~~^\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost\n",
    "!pip install google.colab"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T12:09:36.541690700Z",
     "start_time": "2023-07-31T12:09:25.843991300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T12:09:08.719210Z",
     "start_time": "2023-07-31T12:09:04.588277200Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcatboost\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CatBoostRegressor\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mean_absolute_error\n\u001B[1;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Seed the random number generator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 2023\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mount Google Drive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "DATA_PATH = '/content/drive/MyDrive/data-totalenergies/'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T11:35:22.687416100Z",
     "start_time": "2023-07-31T11:35:22.502085Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\michael\\AppData\\Local\\Temp\\ipykernel_11424\\973339120.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv('../TotalEnergies/data/Train.csv', parse_dates=['travel_date'], dayfirst=False)\n"
     ]
    }
   ],
   "source": [
    "# Load training data, reshape, add departure time as an integer number of seconds and add day of week:\n",
    "df = pd.read_csv(os.path.join(DATA_PATH,'Train.csv'), parse_dates=['travel_date'], dayfirst=False)\n",
    "train = df.groupby(['ride_id', 'travel_date', 'travel_time', 'travel_from', 'max_capacity']).size().reset_index(name='Count') #sort=False if needed?\n",
    "train[\"travel_time\"] = train[\"travel_time\"].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))\n",
    "train['day'] = train['travel_date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T11:35:33.769929700Z",
     "start_time": "2023-07-31T11:35:33.744888600Z"
    }
   },
   "outputs": [],
   "source": [
    "# The same for the test data\n",
    "test = pd.read_csv(os.path.join(DATA_PATH,'Test.csv'), parse_dates=['travel_date'], dayfirst=False).drop(['car_type', 'travel_to'], axis=1)\n",
    "test[\"travel_time\"] = test[\"travel_time\"].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))\n",
    "test['day'] = test['travel_date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T11:35:34.642471Z",
     "start_time": "2023-07-31T11:35:34.625817800Z"
    }
   },
   "outputs": [],
   "source": [
    "# The sample submission file\n",
    "sample = pd.read_csv(os.path.join(DATA_PATH,'SampleSubmission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T11:35:35.577228Z",
     "start_time": "2023-07-31T11:35:35.560218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine training and test data for now, so that we can add uber movement data all in one go\n",
    "train['t'] = 0\n",
    "test['t'] = 1\n",
    "X = pd.concat([train, test], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T11:35:36.628169300Z",
     "start_time": "2023-07-31T11:35:36.547102300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Daily Mean Travel Time (Seconds)       Date\n0                             196.0 2017-10-01",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Daily Mean Travel Time (Seconds)</th>\n      <th>Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>196.0</td>\n      <td>2017-10-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load travel times from Uber movement data ( 3 x 3month periods)\n",
    "\"\"\"\n",
    "t1 = pd.read_csv('../TotalEnergies/data/Travel_Times_Daily_1.csv',parse_dates=['Date'])\n",
    "t2 = pd.read_csv('../TotalEnergies/data/Travel_Times_Daily_2.csv',parse_dates=['Date'])\n",
    "t3 = pd.read_csv('../TotalEnergies/data/Travel_Times_Daily_3.csv',parse_dates=['Date'])\n",
    "\"\"\"\n",
    "\n",
    "t4 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Awendo.csv'),parse_dates=['Date'])\n",
    "t5 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_HomaBay.csv'),parse_dates=['Date'])\n",
    "t6 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Kehancha.csv'),parse_dates=['Date'])\n",
    "t7 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_KenduBay.csv'),parse_dates=['Date'])\n",
    "t8 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Keroka.csv'),parse_dates=['Date'])\n",
    "t9 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Keumbu.csv'),parse_dates=['Date'])\n",
    "t10 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Kijauri.csv'),parse_dates=['Date'])\n",
    "t11 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Kisii.csv'),parse_dates=['Date'])\n",
    "t12 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Mbita.csv'),parse_dates=['Date'])\n",
    "t13 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Migori.csv'),parse_dates=['Date'])\n",
    "t14 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Ndhiwa.csv'),parse_dates=['Date'])\n",
    "t15 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Nyachenge.csv'),parse_dates=['Date'])\n",
    "t16 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Oyugis.csv'),parse_dates=['Date'])\n",
    "t17 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Rodi.csv'),parse_dates=['Date'])\n",
    "t18 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Rongo.csv'),parse_dates=['Date'])\n",
    "t19 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Sirare.csv'),parse_dates=['Date'])\n",
    "t20 = pd.read_csv(os.path.join(DATA_PATH,'Travel_Times_Sori.csv'),parse_dates=['Date'])\n",
    "\n",
    "travel_times = pd.concat([t4, t5, t6, t7, t8, t9, t10, t11, t12, t13, t14, t15, t16, t17, t18, t19, t20], ignore_index=True)\n",
    "travel_times = travel_times.fillna(method='ffill')[['Daily Mean Travel Time (Seconds)', 'Date']]\n",
    "travel_times['Date'] = pd.to_datetime(travel_times['Date'])\n",
    "travel_times.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T11:35:37.889635500Z",
     "start_time": "2023-07-31T11:35:37.855463600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   ride_id  travel_time travel_from  max_capacity  Count  day  t       Date  \\\n0     1442          435      Migori            49    1.0    1  0 2017-10-17   \n\n   Daily Mean Travel Time (Seconds)  \n0                             532.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ride_id</th>\n      <th>travel_time</th>\n      <th>travel_from</th>\n      <th>max_capacity</th>\n      <th>Count</th>\n      <th>day</th>\n      <th>t</th>\n      <th>Date</th>\n      <th>Daily Mean Travel Time (Seconds)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1442</td>\n      <td>435</td>\n      <td>Migori</td>\n      <td>49</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2017-10-17</td>\n      <td>532.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with our contest data\n",
    "X['Date'] = X['travel_date']\n",
    "X.set_index('travel_date', inplace=True)\n",
    "X = X.merge(travel_times, how='left', on='Date')\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T11:35:39.192523100Z",
     "start_time": "2023-07-31T11:35:39.165693600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = CatBoostRegressor(iterations=100, \n",
    "                          depth=8, \n",
    "                          learning_rate=0.6, \n",
    "                          loss_function='MAE', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T11:35:41.521451300Z",
     "start_time": "2023-07-31T11:35:41.497927500Z"
    }
   },
   "outputs": [],
   "source": [
    "in_cols = ['travel_time', 'travel_from', 'max_capacity', 'day'] #'Daily Mean Travel Time (Seconds)' as an option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T11:35:45.080773700Z",
     "start_time": "2023-07-31T11:35:42.262138600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<catboost.core.CatBoostRegressor at 0x1439eb2e450>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "tr = X.loc[X.t == 0]\n",
    "model.fit(tr[in_cols], tr['Count'], cat_features=['travel_from', 'max_capacity', 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T11:35:46.425061Z",
     "start_time": "2023-07-31T11:35:46.393651600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0238402948993057\n"
     ]
    }
   ],
   "source": [
    "# Score model\n",
    "print(mean_absolute_error(model.predict(tr[in_cols]), tr['Count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T11:35:55.571554300Z",
     "start_time": "2023-07-31T11:35:55.539933800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   ride_id  number_of_ticket\n0     4446          0.000000\n1    13962          0.000000\n2     5569          0.000000\n3     1675          0.000000\n4     5711          0.000000\n5     2417          9.870357\n6    15010         10.744758\n7     1823          7.306642\n8    15191         11.974640\n9    14402        -12.318206",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ride_id</th>\n      <th>number_of_ticket</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4446</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13962</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5569</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1675</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5711</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2417</td>\n      <td>9.870357</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>15010</td>\n      <td>10.744758</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1823</td>\n      <td>7.306642</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>15191</td>\n      <td>11.974640</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>14402</td>\n      <td>-12.318206</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions and append to the sample submission data, and save as csv\n",
    "te = X.loc[X.t == 1]\n",
    "te[in_cols].head()\n",
    "te = X.loc[X.t == 1]\n",
    "sample['number_of_ticket'][5:] = model.predict(te[in_cols])[5:] # Ignore the warning\n",
    "sample.to_csv('catboost_solution_2.79.csv', index=False)\n",
    "sample.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "     Feature Id  Importances\n0   travel_time    37.942220\n1   travel_from    33.787444\n2           day    19.550092\n3  max_capacity     8.720244",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature Id</th>\n      <th>Importances</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>travel_time</td>\n      <td>37.942220</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>travel_from</td>\n      <td>33.787444</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>day</td>\n      <td>19.550092</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max_capacity</td>\n      <td>8.720244</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot feature importance\n",
    "model.get_feature_importance(prettified=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-31T11:31:16.510318700Z",
     "start_time": "2023-07-31T11:31:16.495825600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
